{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science 2021\n",
    "\n",
    "# Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 | Titanic: data preprocessing and imputation\n",
    "<span style=\"background-color: #ccfff2\"> *Note: You can find tutorials for NumPy and Pandas under 'Useful tutorials' in Moodle.*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [Titanic dataset](https://www.kaggle.com/c/titanic) from Kaggle, and complete the following exercises. You will need to create a Kaggle account unless you already have one, but it is very straightforward. \n",
    "\n",
    "The dataset consists of personal information of all the passengers on board the Titanic, along with the information whether they survived the iceberg collision or not.\n",
    "\n",
    "1. Your first task is to read the data file and print the shape of the data. \n",
    "\n",
    "    <span style=\"background-color: #ccfff2\"> *Hint 1: You can read them into a Pandas dataframe if you wish.*</span>\n",
    "    \n",
    "    <span style=\"background-color: #ccfff2\"> *Hint 2: The shape of the data should be (891, 12).*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "# importing pandas and numpy libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loading data\n",
    "titanic = pd.read_csv(r'C:\\Users\\Diana Crowe\\Documents\\Classes\\Introduction to Data Science\\Exercises\\train.csv')\n",
    "\n",
    "# printing shape of the data\n",
    "print(np.shape(titanic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Let's look at the data and get started with some preprocessing. Some of the columns, e.g <span style=\"background-color: #ccfff2\"> *Name*</span>, simply identify a person and are not useful for prediction tasks. Try to identify these columns, and remove them.\n",
    "\n",
    "    <span style=\"background-color: #ccfff2\"> *Hint: The shape of the data should now be (891, 10).*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Peeking at the Starting data:\n",
      "------------------------------------------------------------\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "-----------------------------------------------------------\n",
      "New data after removing columns \"PaggengerID\" and \"Name\":\n",
      "------------------------------------------------------------\n",
      "  Survived Pclass     Sex   Age SibSp Parch            Ticket     Fare Cabin  \\\n",
      "0        0      3    male  22.0     1     0         A/5 21171     7.25   NaN   \n",
      "1        1      1  female  38.0     1     0          PC 17599  71.2833   C85   \n",
      "2        1      3  female  26.0     0     0  STON/O2. 3101282    7.925   NaN   \n",
      "3        1      1  female  35.0     1     0            113803     53.1  C123   \n",
      "4        0      3    male  35.0     0     0            373450     8.05   NaN   \n",
      "\n",
      "  Embarked  \n",
      "0        S  \n",
      "1        C  \n",
      "2        S  \n",
      "3        S  \n",
      "4        S  \n"
     ]
    }
   ],
   "source": [
    "print('-----------------------------------------------------------')\n",
    "print('Peeking at the Starting data:')\n",
    "print('------------------------------------------------------------')\n",
    "# view first five rows of the dataset to identify the columns not useful for prediction tasks\n",
    "print(titanic.head())\n",
    "\n",
    "# changing the data from pandas to numpy so that I can easily delete dolumns PassengerId and Name\n",
    "np_values = titanic.values\n",
    "np_new_values = np.delete(np_values, [0, 3], 1)\n",
    "\n",
    "print()\n",
    "print('-----------------------------------------------------------')\n",
    "print('New data after removing columns \"PaggengerID\" and \"Name\":')\n",
    "print('------------------------------------------------------------')\n",
    "# changing the data back into a pandas dataframe\n",
    "new_values = pd.DataFrame(np_new_values, columns=['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'])\n",
    "\n",
    "print(new_values.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The column <span style=\"background-color: #ccfff2\">*Cabin*</span> contains a letter and a number. A clever data scientist might conclude that the letter stands for their deck level on the ship (which is indeed true) and that keeping just the deck information might improve the results of a classifier predicting an output variable. Add a new column to the dataset, which consists simply of the deck letter. \n",
    "\n",
    "    <span style=\"background-color: #ccfff2\">*Hint: The deck letters should be ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'T'].*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "Checking the NULL values in the different columns:\n",
      "-----------------------------------------------------------\n",
      "Survived      0\n",
      "Pclass        0\n",
      "Sex           0\n",
      "Age         177\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Ticket        0\n",
      "Fare          0\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "Deck          0\n",
      "dtype: int64\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "Peeking at the new column \"Deck\" containing the first letter of \"Cabin\":\n",
      "--------------------------------------------------------------------------\n",
      "  Survived Pclass     Sex   Age SibSp Parch            Ticket     Fare Cabin  \\\n",
      "0        0      3    male  22.0     1     0         A/5 21171     7.25   NaN   \n",
      "1        1      1  female  38.0     1     0          PC 17599  71.2833   C85   \n",
      "2        1      3  female  26.0     0     0  STON/O2. 3101282    7.925   NaN   \n",
      "3        1      1  female  35.0     1     0            113803     53.1  C123   \n",
      "4        0      3    male  35.0     0     0            373450     8.05   NaN   \n",
      "\n",
      "  Embarked Deck  \n",
      "0        S    n  \n",
      "1        C    C  \n",
      "2        S    n  \n",
      "3        S    C  \n",
      "4        S    n  \n"
     ]
    }
   ],
   "source": [
    "# Checking the NULL values in the different columns\n",
    "print('-----------------------------------------------------------')\n",
    "print('Checking the NULL values in the different columns:')\n",
    "print('-----------------------------------------------------------')\n",
    "print(new_values.isnull().sum())\n",
    "\n",
    "print()\n",
    "# the previous command told us that there are 687 NULL values (NaN) in the columns Cabin\n",
    "# 687 NaN values out of a total of 891 values is a lot of missing values!\n",
    "\n",
    "# Adding a column Deck and temporarily filling it with ones\n",
    "new_values['Deck'] = 0\n",
    "new_values.loc[new_values.Deck == 0, 'Deck'] = 1\n",
    "\n",
    "# assigning \"string\" type to the Cabin column and extracting the first element to put into the Deck column\n",
    "new_values['Deck'] = new_values['Cabin'].astype(str).str[0]\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Peeking at the new column \"Deck\" containing the first letter of \"Cabin\":')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print(new_values.head())\n",
    "\n",
    "# comment: in the case of NaN, the first letter is a small n, which doesn't conflict with other deck letters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. You’ll notice that some of the columns, such as the previously added deck number, are [categorical](https://en.wikipedia.org/wiki/Categorical_variable). Their string representation is not efficient for further computation. First create two lists, one with the continuous variables and one with the categorical ones. Then, transform the categorical values into their numeric representation, so that a unique integer id corresponds to each distinct category. \n",
    "\n",
    "    <span style=\"background-color: #ccfff2\">*Hint 1: Pandas can do this for you.*</span> \n",
    "\n",
    "    <span style=\"background-color: #ccfff2\">*Hint 2: Look into label encoding.*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Survived Pclass  Sex   Age SibSp Parch            Ticket     Fare  Cabin  \\\n",
      "0        0      3    1  22.0     1     0         A/5 21171     7.25     -1   \n",
      "1        1      1    0  38.0     1     0          PC 17599  71.2833     81   \n",
      "2        1      3    0  26.0     0     0  STON/O2. 3101282    7.925     -1   \n",
      "3        1      1    0  35.0     1     0            113803     53.1     55   \n",
      "4        0      3    1  35.0     0     0            373450     8.05     -1   \n",
      "\n",
      "   Embarked  Deck  \n",
      "0         2     8  \n",
      "1         0     2  \n",
      "2         2     8  \n",
      "3         2     2  \n",
      "4         2     8  \n"
     ]
    }
   ],
   "source": [
    "# Creating the two lists:\n",
    "list_categorical = ['Sex','Cabin','Embarked','Deck']\n",
    "list_numerical = ['Survived', 'Pclass','Age','SibSp','Parch', 'Fare']\n",
    "\n",
    "#  Note! I left the column \"Ticket\" out as it's a very problematic one. Most tickets have plain numbers,\n",
    "# but there are a few of them that have strings in front of the number. The columns \"Ticket\" doesn't really\n",
    "# fit very well with either categorical or continuous variables as it currently stands.\n",
    "\n",
    "# If I want to create a table with all the Categorical variables\n",
    "Categorical = new_values[['Sex','Cabin','Embarked','Deck']]\n",
    "# If I want to create a table with all the Continuous variables\n",
    "Continuous = new_values[['Survived', 'Pclass','Age','SibSp','Parch', 'Fare']]\n",
    "\n",
    "\n",
    "# Transforming Categorical values into a numerical representation using label encoding\n",
    "new_values[list_categorical] = new_values[list_categorical].astype('category') # changing to categorical\n",
    "#new_values.dtypes # this gives a printout of the types in our dataframe\n",
    "\n",
    "new_values['Sex'] = new_values['Sex'].cat.codes   # for some reason I had to encode one at a time...\n",
    "new_values['Cabin'] = new_values['Cabin'].cat.codes\n",
    "new_values['Embarked'] = new_values['Embarked'].cat.codes\n",
    "new_values['Deck'] = new_values['Deck'].cat.codes\n",
    "print(new_values.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Next, let's look into missing value **imputation**. Some of the rows in the data have missing values, e.g when the cabin number of a person is unknown. Most machine learning algorithms have trouble with missing values, and they need to be handled during the preprocessing:\n",
    "\n",
    "    a) For continuous values, replace the missing values with the average of the non-missing values of that column.\n",
    "\n",
    "    b) For discrete and categorical values, replace the missing values with the mode of the column.\n",
    "\n",
    "    <span style=\"background-color: #ccfff2\">*Remember: In the previous step we converted categorical values into numeric representations. You can use the lists we created in step 4, to see which variables are discrete (even though we are using their numeric representation).*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am not really sure of what we want to do in this step..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. At this point, all data is numeric. Write the data, with the modifications we made, to a  <span style=\"background-color: #ccfff2\"> .csv</span> file. Then, write another file, this time in <span style=\"background-color: #ccfff2\">JSON</span> format, with the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\n",
    "#    {\n",
    "#        \"Deck\": 0,\n",
    "#        \"Age\": 20,\n",
    "#        \"Survived\", 0\n",
    "#        ...\n",
    "#    },\n",
    "#    {\n",
    "#        ...\n",
    "#    }\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a csv file\n",
    "new_values.to_csv(index=False)\n",
    "\n",
    "# writing to a JSON format:\n",
    "data_titanic = new_values.to_json(orient='index')\n",
    "# print(data_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the records and try to see if there is any evident pattern in terms of chances of survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to submit your code on Moodle. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 | Titanic 2.0: exploratory data analysis\n",
    "\n",
    "In this exercise, we’ll continue to study the Titanic dataset from the last exercise. Now that we have preprocessed it a bit, it’s time to do some exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First consider each feature variable in turn. For each categorical variable, find out the mode, i.e., the most frequent value. For numerical variables, calculate the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a quick function to calculate the mean\n",
    "def my_mean(sample):\n",
    "    return sum(sample) / len(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next, combine the modes of the categorical variables, and the medians of the numerical variables, to construct an imaginary “average survivor”. This \"average survivor\" should represent the typical passenger of the class of passengers who survived. Also following the same principle, construct the “average non-survivor”. \n",
    "\n",
    "    <span style=\"background-color: #ccfff2\">*Hint: What are the average/most frequent variable values for a non-survivor?*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next, let's study the distributions of the variables in the two groups (survivor/non-survivor). How well do the average cases represent the respective groups? Can you find actual passengers that are very similar to the (average) representative of their own group? Can you find passengers that are very similar to the (average) representative of the other group? \n",
    "\n",
    "    <span style=\"background-color: #ccfff2\">*Note: You are free to choose your methods: non-graphical/graphical, static/interactive - anything goes.*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. To give a more complete picture of the two groups (survivor/non-survivor), provide graphical displays of the distribution of the variables in each group whenever appropriate (not, e.g., on the ticket number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Next, let's start the analysis by looking into pairwise and multivariate relationships between the variables in the two groups. Try to visualize two variables at a time using, e.g., scatter plots and use a different color to display the survival status.\n",
    "\n",
    "    <span style=\"background-color: #ccfff2\">*Hint 1: You can also check out Seaborn's pairplot function, if you wish.*</span>\n",
    "\n",
    "    <span style=\"background-color: #ccfff2\">*Hint 2: To better show many data points with the same value for a given variable, you can use either transparency or ‘jitter’.*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Finally, recall the preprocessing we did in the first exercise. Can you say something about the effect of the choices that were made, in particular, to use the mode or the mean to impute missing values, instead of, for example, ignoring passengers with missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Use this (markdown) cell for your written answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to submit your code on Moodle. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 | Working with text data 2.0\n",
    "\n",
    "This exercise is related to the second exercise last week. Find your self-made <span style=\"background-color: #ccfff2\">pos.txt</span> and <span style=\"background-color: #ccfff2\">neg.txt</span>, or if you didn’t complete the exercise, you can find the example solutions on Moodle after Tuesday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find the most common words in each file (positive and negative). What are they? Are some of them clearly general terms relating to the nature of the data, and not just the emotion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compute a [TF/IDF](https://en.wikipedia.org/wiki/Tf–idf) vector for each of the text files, and make them into a <span style=\"background-color: #ccfff2\">2 x m</span> matrix, where <span style=\"background-color: #ccfff2\">m</span> is the number of unique words in the data. The problem with using the most common words in a review to analyze its contents is that words that are common overall will be common in all reviews. This means that they probably don’t tell anything about a specific review. TF/IDF stands for Term Frequency / Inverse Document Frequency (here the reviews are the documents), and is designed to help by taking into consideration not just the number of times a term occurs (term frequency), but also how many times a word exists in other reviews as well (inverse document frequency). You can use any variant of the formula, and ready-made implementations. <span style=\"background-color: #ccfff2\">*Hint: You can use [sklearn](http://scikit-learn.org/).*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. List the words with the highest TF/IDF score in each class (positive | negative), and compare them to the most common words. What do you notice? Did TF/IDF work as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot the words in each class and their corresponding TF/IDF scores. Note that there will be a lot of words, so you’ll have to think carefully to make your chart clear! If you can’t plot them all, plot a subset – think about how you should choose this subset. \n",
    "\n",
    "    <span style=\"background-color: #ccfff2\">*Hint: you can use word clouds. But feel free to challenge yourselves to think of any other meaningful way to visualize this information!*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to submit your code on Moodle. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 | Junk charts\n",
    "\n",
    "There’s a thriving community of chart enthusiasts who keep looking for statistical graphics that they find inappropriate, and which they call “junk charts”, and who often also propose fixes to improve them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find at least three statistical visualizations that you think aren’t very good, and identify their problems. Copying examples from various junk chart websites isn’t accepted – you should find your own junk charts. You should be able to find good (or rather, bad) examples quite easily since a large fraction of charts have at least some issues. The examples you choose should also have different problems, so don’t look for three column or bar charts whose axes don’t begin at zero. Try to find as interesting and diverse examples as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Try to produce improved versions of the charts you selected. The data is of course often not available, but perhaps you can try to extract it, at least approximately, from the chart. Or perhaps you can simulate data that looks similar enough to make the point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submit a PDF with all the charts (the ones you found and the ones you produced).**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
